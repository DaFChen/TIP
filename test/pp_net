from utils import load_data
from matplotlib import pyplot as plt
from layers import *

path = "C:\\Users\\sangsq\\Desktop\\pj\\FM-PSEP\\data\\"
pp_net = load_data(path, [])['pp_adj'].tocoo()
indices = torch.LongTensor(np.concatenate((pp_net.col.reshape(1, -1),
                                       pp_net.row.reshape(1, -1)), axis=0))
n_node = pp_net.shape[0]
n_edge = indices.shape[1]
train_mask = np.random.binomial(1, 0.9, n_node)
test_mask = 1 - train_mask

hid1 = 32
hid2 = 16

x = sparse_id(n_node)


class PP_Encoder(torch.nn.Module):
    def __init__(self):
        super(PP_Encoder, self).__init__()
        self.conv1 = GCNConv(n_node, hid1, cached=True)
        self.conv2 = GCNConv(hid1, hid2, cached=True)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = F.normalize(x, dim=1)
        # x = F.dropout(x, training=self.training)
        x = self.conv2(x, edge_index)
        return x


model = GAE(PP_Encoder())
device = torch.device('cpu')
optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
# optimizer = torch.optim.SGD(model.parameters(), lr=10)



tmp = []

for i in range(40):
    model.train()
    optimizer.zero_grad()

    z = model.encoder(x, indices)
    pos_indices = indices
    neg_indices = negative_sampling(indices, n_node)

    pos_score = model.decoder(z, pos_indices)
    neg_score = model.decoder(z, neg_indices)


    pos_loss = F.binary_cross_entropy(pos_score, torch.ones(n_edge))
    neg_loss = F.binary_cross_entropy(neg_score, torch.zeros(n_edge))

    # loss = pos_loss + neg_loss
    loss = neg_loss + pos_loss

    pos_acc = (pos_score > 0.5).sum().to(torch.float) / float(n_edge)
    neg_acc = (neg_score < 0.5).sum().to(torch.float) / float(n_edge)

    print('pos_loss: ', pos_loss.tolist(), '\t',
          'neg_loss: ', neg_loss.tolist(), '\t',
          'pos_acc: ', pos_acc.tolist(), '\t',
          'neg_acc ', neg_acc.tolist())

    loss.backward()
    optimizer.step()

