[hpc4590@cac107 ~]$ python TIP/df_distmult.py 
loading data
remove  0  isolated drugs:  []
remove finished
1097  polypharmacy side effects
data has been loaded
cuda
  0   loss:         auprc:0.4948   auroc:0.5001   ap@50:0.5003    
model training ...
  1   time:3.60
  2   time:3.61
  3   time:3.54
  4   time:3.57
  5   time:3.57
  6   time:3.54
  7   time:3.54
  8   time:3.55
  9   time:3.54
 10   loss:1.4024   auprc:0.5129   auroc:0.5262   ap@50:0.5183    time:10.6
 11   time:3.53
 12   time:3.57
 13   time:3.56
 14   time:3.55
 15   time:3.55
 16   time:3.56
 17   time:3.55
 18   time:3.56
 19   time:3.54
 20   loss:1.3743   auprc:0.5508   auroc:0.5789   ap@50:0.5560    time:10.6
 21   time:3.53
 22   time:3.56
 23   time:3.55
 24   time:3.57
 25   time:3.55
 26   time:3.56
 27   time:3.53
 28   time:3.55
 29   time:3.55
 30   loss:1.3351   auprc:0.6163   auroc:0.6549   ap@50:0.6209    time:10.7
 31   time:3.55
 32   time:3.54
 33   time:3.54
 34   time:3.55
 35   time:3.54
 36   time:3.57
 37   time:3.54
 38   time:3.56
 39   time:3.55
 40   loss:1.2722   auprc:0.6869   auroc:0.7267   ap@50:0.6906    time:10.6
 41   time:3.52
 42   time:3.55
 43   time:3.55
 44   time:3.56
 45   time:3.55
 46   time:3.56
 47   time:3.56
 48   time:3.52
 49   time:3.55
 50   loss:1.1889   auprc:0.7391   auroc:0.7772   ap@50:0.7417    time:10.6
 51   time:3.54
 52   time:3.56
 53   time:3.55
 54   time:3.55
 55   time:3.55
 56   time:3.56
 57   time:3.55
 58   time:3.56
 59   time:3.56
 60   loss:1.1043   auprc:0.7719   auroc:0.8082   ap@50:0.7737    time:10.6
 61   time:3.54
 62   time:3.54
 63   time:3.53
 64   time:3.56
 65   time:3.55
 66   time:3.54
 67   time:3.56
 68   time:3.57
 69   time:3.56
 70   loss:1.0376   auprc:0.7934   auroc:0.8279   ap@50:0.7944    time:10.6
 71   time:3.54
 72   time:3.56
 73   time:3.54
 74   time:3.56
 75   time:3.55
 76   time:3.55
 77   time:3.55
 78   time:3.57
 79   time:3.56
 80   loss:0.9917   auprc:0.8095   auroc:0.8413   ap@50:0.8096    time:10.6
 81   time:3.55
 82   time:3.54
 83   time:3.54
 84   time:3.56
 85   time:3.54
 86   time:3.54
 87   time:3.55
 88   time:3.58
 89   time:3.54
 90   loss:0.9618   auprc:0.8209   auroc:0.8504   ap@50:0.8203    time:10.6
 91   time:3.55
 92   time:3.55
 93   time:3.56
 94   time:3.53
 95   time:3.55
 96   time:3.55
 97   time:3.55
 98   time:3.56
 99   time:3.56
100   loss:0.9422   auprc:0.8285   auroc:0.8561   ap@50:0.8272    time:10.6
/global/home/hpc4590/.conda/envs/hgcn/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MyGAE. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/global/home/hpc4590/.conda/envs/hgcn/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
/global/home/hpc4590/.conda/envs/hgcn/lib/python3.7/site-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MultiInnerProductDecoder. It won't be checked for correctness upon loading.
  "type " + obj.__name__ + ". It won't be checked "
tensor([0.9807, 0.8551, 0.9674,  ..., 0.9554, 0.4776, 0.8317], device='cuda:0',
       grad_fn=<SigmoidBackward>)
torch.Size([924708])
File: TIP/df_distmult.py
Function: train at line 96

Line # Max usage   Peak usage diff max diff peak  Line Contents
===============================================================
    96                                           @profile
    97                                           def train():
    98   264.16M      282.00M  329.00K -536.00M      model.train()
    99                                           
   100   264.16M      282.00M    0.00B    0.00B      optimizer.zero_grad()
   101   264.20M      282.00M   40.50K    0.00B      z = model.encoder(data.d_feat, data.train_idx, data.train_et, data.train_range, data.x_norm)
   102                                           
   103   264.20M      282.00M    0.00B    0.00B      pos_index = data.train_idx
   104   392.20M      538.00M  128.00M  256.00M      neg_index = typed_negative_sampling(data.train_idx, n_drug, data.train_range).to(device)
   105                                           
   106     2.40G        2.92G    2.02G    2.40G      pos_score = model.decoder(z, pos_index, data.train_et)
   107     4.42G        5.38G    2.02G    2.46G      neg_score = model.decoder(z, neg_index, data.train_et)
   108                                           
   109                                               # pos_loss = F.binary_cross_entropy(pos_score, torch.ones(pos_score.shape[0]).cuda())
   110                                               # neg_loss = F.binary_cross_entropy(neg_score, torch.ones(neg_score.shape[0]).cuda())
   111     4.45G        4.88G   31.76M -510.00M      pos_loss = -torch.log(pos_score + EPS).mean()
   112     4.48G        4.88G   31.76M    0.00B      neg_loss = -torch.log(1 - neg_score + EPS).mean()
   113     4.48G        4.88G  512.00B    0.00B      loss = pos_loss + neg_loss
   114                                               # loss = pos_loss
   115                                           
   116   455.73M        5.88G   -4.03G 1020.00M      loss.backward()
   117   455.73M      920.00M    0.00B   -4.98G      optimizer.step()
   118   264.16M      920.00M -191.57M    0.00B  
   119                                               # record = np.zeros((3, n_et_dd))  # auprc, auroc, ap
   120                                               # for i in range(data.train_range.shape[0]):
   121                                               #     [start, end] = data.train_range[i]
   122                                               #     p_s = pos_score[start: end]
   123                                               #     n_s = neg_score[start: end]
   124                                           
   125                                               #     pos_target = torch.ones(p_s.shape[0])
   126                                               #     neg_target = torch.zeros(n_s.shape[0])
   127                                           
   128                                               #     score = torch.cat([p_s, n_s])
   129                                               #     target = torch.cat([pos_target, neg_target])
   130                                           
   131                                               #     record[0, i], record[1, i], record[2, i] = auprc_auroc_ap(target, score)
   132                                           
   133                                               # train_record[epoch] = record
   134                                               # [auprc, auroc, ap] = record.sum(axis=1) / n_et_dd
   135                                               # train_out[epoch] = [auprc, auroc, ap]
   136                                           
   137                                               # print('{:3d}   loss:{:0.4f}   auprc:{:0.4f}   auroc:{:0.4f}   ap@50:{:0.4f}'
   138                                               #       .format(epoch, loss.tolist(), auprc, auroc, ap))
   139                                           
   140   455.73M      920.00M    0.00B    0.00B      return z, loss