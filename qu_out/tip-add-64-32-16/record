=========================== SUMMARY ===========================

average_training_time: 21.47 s/epoch
peak_gpu_memory usage: 20.89 G

  0   loss:         auprc:0.5063   auroc:0.5016   ap@50:0.5116 
100   loss:0.7188   auprc:0.8941   auroc:0.9173   ap@50:0.8950    time:28.5

=========================== DETAILS ===========================

[hpc4590@cac107 ~]$ python TIP/tip-add.py 
loading data
remove  0  isolated drugs:  []
remove finished
1097  polypharmacy side effects
data has been loaded
cuda
  0   loss:         auprc:0.5063   auroc:0.5016   ap@50:0.5116    
model training ...
  1   time:21.46
  2   time:21.50
  3   time:21.47
  4   time:21.48
  5   time:21.45
  6   time:21.49
  7   time:21.47
  8   time:21.49
  9   time:21.47
 10   loss:1.3152   auprc:0.6934   auroc:0.6900   ap@50:0.6964    time:28.6
 11   time:21.41
 12   time:21.45
 13   time:21.50
 14   time:21.67
 15   time:21.48
 16   time:21.48
 17   time:21.45
 18   time:21.46
 19   time:21.45
 20   loss:0.9101   auprc:0.8493   auroc:0.8787   ap@50:0.8511    time:28.6
 21   time:21.35
 22   time:21.47
 23   time:21.49
 24   time:21.44
 25   time:21.47
 26   time:21.49
 27   time:21.45
 28   time:21.44
 29   time:21.43
 30   loss:0.7782   auprc:0.8824   auroc:0.9075   ap@50:0.8836    time:28.5
 31   time:21.39
 32   time:21.44
 33   time:21.47
 34   time:21.45
 35   time:21.46
 36   time:21.44
 37   time:21.47
 38   time:21.44
 39   time:21.45
 40   loss:0.7575   auprc:0.8858   auroc:0.9100   ap@50:0.8870    time:28.5
 41   time:21.35
 42   time:21.44
 43   time:21.46
 44   time:21.43
 45   time:21.43
 46   time:21.46
 47   time:21.43
 48   time:21.40
 49   time:21.42
 50   loss:0.7504   auprc:0.8870   auroc:0.9108   ap@50:0.8881    time:28.5
 51   time:21.36
 52   time:21.41
 53   time:21.44
 54   time:21.42
 55   time:21.43
 56   time:21.45
 57   time:21.45
 58   time:21.43
 59   time:21.43
 60   loss:0.7521   auprc:0.8879   auroc:0.9115   ap@50:0.8890    time:28.5
 61   time:21.35
 62   time:21.42
 63   time:21.47
 64   time:21.46
 65   time:21.44
 66   time:21.42
 67   time:21.44
 68   time:21.43
 69   time:21.44
 70   loss:0.7418   auprc:0.8881   auroc:0.9118   ap@50:0.8892    time:28.5
 71   time:21.33
 72   time:21.42
 73   time:21.44
 74   time:21.40
 75   time:21.43
 76   time:21.44
 77   time:21.44
 78   time:21.43
 79   time:21.43
 80   loss:0.7370   auprc:0.8896   auroc:0.9131   ap@50:0.8906    time:28.5
 81   time:21.33
 82   time:21.40
 83   time:21.46
 84   time:21.43
 85   time:21.42
 86   time:21.43
 87   time:21.42
 88   time:21.43
 89   time:21.45
 90   loss:0.7272   auprc:0.8920   auroc:0.9153   ap@50:0.8930    time:28.4
 91   time:21.32
 92   time:21.41
 93   time:21.44
 94   time:21.41
 95   time:21.41
 96   time:21.43
 97   time:21.44
 98   time:21.43
 99   time:21.43
100   loss:0.7188   auprc:0.8941   auroc:0.9173   ap@50:0.8950    time:28.5


Line # Max usage   Peak usage diff max diff peak  Line Contents
===============================================================
   169                                           @profile        # remove this for training on CPU
   170                                           ##################################################
   171                                           def train():
   172     3.32G        3.49G    0.00B   -1.85G      model.train()
   173                                           
   174     3.32G        3.49G    0.00B    0.00B      optimizer.zero_grad()
   175     6.32G        8.32G    2.99G    4.83G      z = model.encoder(data.d_feat, data.dd_train_idx, data.dd_train_et, data.dd_train_range, data.d_norm, data.p_feat, data.pp_train_indices, data.dp_edge_index, data.dp_range_list)
   176                                           
   177     6.32G        6.47G    0.00B   -1.85G      pos_index = data.dd_train_idx
   178     6.44G        6.60G  127.05M  126.00M      neg_index = typed_negative_sampling(data.dd_train_idx, data.n_drug, data.dd_train_range).to(device)
   179                                           
   180                                               # pos_score = checkpoint(model.decoder, z, pos_index, data.dd_train_et)
   181                                               # neg_score = checkpoint(model.decoder, z, neg_index, data.dd_train_et)
   182     8.46G        8.99G    2.02G    2.40G      pos_score = model.decoder(z, pos_index, data.dd_train_et)
   183    10.48G       11.45G    2.02G    2.46G      neg_score = model.decoder(z, neg_index, data.dd_train_et)
   184                                           
   185                                               # pos_loss = F.binary_cross_entropy(pos_score, torch.ones(pos_score.shape[0]).cuda())
   186                                               # neg_loss = F.binary_cross_entropy(neg_score, torch.ones(neg_score.shape[0]).cuda())
   187    10.51G       10.96G   31.76M -510.00M      pos_loss = -torch.log(pos_score + EPS).mean()
   188    10.54G       10.96G   31.76M    0.00B      neg_loss = -torch.log(1 - neg_score + EPS).mean()
   189    10.54G       10.96G  512.00B    0.00B      loss = pos_loss + neg_loss
   190                                               # loss = pos_loss
   191                                           
   192     3.51G       20.89G   -7.02G    9.94G      loss.backward()
   193     3.52G        3.99G    5.73M  -16.90G      optimizer.step()
   194   347.68M        3.99G   -3.18G    0.00B  
   195     3.52G        3.99G    0.00B    0.00B      return z, loss
